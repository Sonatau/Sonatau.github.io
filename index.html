<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>私人海域</title><meta name="description" content="佳期不可再，风雨杳如年"><meta name="keywords" content="test"><meta name="author" content="Sonata,sonatau@163.com"><meta name="copyright" content="Sonata"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://tva1.sinaimg.cn/large/007S8ZIlly1ghwjtdrp4tj30rs0rsjwe.jpg"><link rel="canonical" href="http://yluy.gitee.io/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="website"><meta property="og:title" content="私人海域"><meta property="og:url" content="http://yluy.gitee.io/"><meta property="og:site_name" content="私人海域"><meta property="og:description" content="佳期不可再，风雨杳如年"><meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlly1ghwjow3dndj30jg0jgdgq.jpg"><meta property="article:published_time" content="2020-08-29T13:57:58.663Z"><meta property="article:modified_time" content="2020-08-29T13:57:58.663Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.0.2',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2020-08-29 21:57:58'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 5.0.2"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghwjow3dndj30jg0jgdgq.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">24</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">3</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(https://tva1.sinaimg.cn/large/007S8ZIlly1ghwkr89vbaj31hc0u0ag1.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">私人海域</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site_title">私人海域</h1><div id="site_subtitle"><span id="subtitle"></span></div></div><div id="scroll_down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/29/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="【机器学习】K近邻算法原理与实践">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi80z5ja2uj31hc0u0ag1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】K近邻算法原理与实践"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/29/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="【机器学习】K近邻算法原理与实践">【机器学习】K近邻算法原理与实践</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-29T13:55:16.000Z" title="发表于 2020-08-29 21:55:16">2020-08-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/">算法原理</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 前言
KNN（K-k-nearest neighbors）又叫做K近邻，是机器学习中相对简单好理解的算法，并且它是唯一一个不需要训练就可以得到预测结果的模型。
我们常说物以类聚，人以群分，大家之所以能够成为朋友，多少是因为身上的某些特质是相近的，K近邻算法借助的就是这个思想。它使用某种方法找到样本空间中距离测试点最近的K个点，以投票表决的方式决定该测试点的标签。
本文将结合阿里云提供的机器学习算法(三): K近邻(k-nearest neighbors)初探与清华大学李航老师的PPT，来具体解释这其中的理论基础和代码实例。
 KNN理论基础
 背景介绍
大家通过视频软件挑选电影的时候，通常会先按照电影的类别进行挑选，例如动作片、爱情片、歌舞片。这些电影有各自的特点，像是动作片的打斗场景一定比爱情片多，它也不会像音乐片一样一言不合就开始跳舞，但又不能完全排除有出现的可能。
总结这三类型的影片所具有的显著特点：打斗、亲吻、跳舞。假设现在用一个元组(a, b, c)来表示，值在0～1之间，Movie = (0.8, 0.1, 0.1)时，就认为这个电影是动作片。那么很自然的，提出了使用一个 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/29/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93/" title="【图像处理】图像轮廓">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi7jwhy37fj31de0rs4fs.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【图像处理】图像轮廓"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/29/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93/" title="【图像处理】图像轮廓">【图像处理】图像轮廓</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-29T04:02:32.000Z" title="发表于 2020-08-29 12:02:32">2020-08-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/openCV/">openCV</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E7%AE%80%E5%8D%95/">简单</a></span></div><div class="content">openCV中可以使用一些函数找到图像轮廓，进而获取目标图像的大小、位置、方向等信息。
下面将针对下图来做图像轮廓的说明：

 查找图像轮廓findCounters
1contours, hierarchy = cv2.findContours( image, mode, method)
式中的返回值为：

contours：返回的轮廓。
hierarchy：图像的拓扑信息（轮廓层次）。

式中的参数为：

image：原始图像。8位单通道图像，所有非零值被处理为1，所有零值保持不变。也就是说灰度图像会被自动处理为二值图像。在实际操作时，可以根据需要，预先使用阈值处理等函数将待查找轮廓的图像处理为二值图像。
mode：轮廓检索模式。
method：轮廓的近似方法。

函数cv2.findContours()的返回值及参数的含义比较丰富，下面对上述返回值和参数逐一做出说明。
 返回值contours
该返回值返回的是一组轮廓信息，类型为list，每个轮廓都是由若干个点所构成的。

coutours[i][j]表示的是第i个轮廓内的第j个点。
len(contours)的结果表示图中找到了 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/" title="【论文阅读】《StarGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bwff3axj318g0p0ac5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《StarGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/" title="【论文阅读】《StarGAN》">【论文阅读】《StarGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-28T02:42:42.000Z" title="发表于 2020-08-28 10:42:42">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content">
论文：《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》
发表时间：CVPR 2018
解决问题：多领域的图像转换问题

 背景
Pix2Pix与CycleGAN分别解决了两个领域之间基于匹配数据和非匹配数据的转换。但是在实际的应用中我们会发现需要大量的多领域转换，例如图1所示，这可能是一个智能修图的场景，用户输入一张人物照片，他希望能够通过选项来调节照片中人物的外貌，比如图中例子的发色、性别、年龄、肤色等。又比如图2，对于同一个人物照片我们希望能够将他转换成各种不一样的表情，从普通的表情转换为愤怒、喜悦和恐惧等。


之前的Pix2Pix和CycleGAN可以非常好地解决领域间转换问题，它们同样可以应用于多领域的转换，但是存在的问题是必须在每两个领域之间进行单独的训练。我们假设场景为图8-3的表情转换，一共有四个领域，分别为中性、生气、喜悦与恐惧，我们将它们从1到4标号。如果使用CycleGAN的话我们可以看到图3，在每两个领域都需要训练两个生成 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8APix2Pix%E3%80%8B/" title="【论文阅读】《Pix2Pix》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bthvkq1j315o0mzwj5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《Pix2Pix》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8APix2Pix%E3%80%8B/" title="【论文阅读】《Pix2Pix》">【论文阅读】《Pix2Pix》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-28T02:41:18.000Z" title="发表于 2020-08-28 10:41:18">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content">
论文：《Image-to-Image Translation with Conditional Adversarial Networks》
发表日期：2017 CVPR

 前言
pix2pix是cGAN的一个变体，能够实现从图像到图像的映射，在从标签映射合成照片、从边缘映射重建对象、图片上色等多类人物的表现较好。它比较适合于监督学习，即图像的输入和它的输出是相互匹配的。所谓匹配数据集是指在训练集中两个互相转换的领域之间有明确的一一对应数据。在工程实践中研究者需要自己收集这些匹配数据，但有时同时采集两个不同领域的匹配数据是麻烦的，通常采用的方案是从更完整的数据中还原简单数据。比如直接将彩色图片通过图像处理的方法转为黑白图片。
训练完成后，pix2pix可以将图像从领域A变换到领域B。下面这张图中，左侧的input和output分别是同一个地方白天和夜晚的照片，看作是不同领域X和Y的两张图，生成器G应尽可能得将input转换成output。

注意，因为匹配数据集的存在，研究者尝试用普通CNN进行图像对图像的变换，但是不能生成清晰逼真的图像，因为CNN会试图让最终的输出接近所有相类似的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ADCGAN%E3%80%8B/" title="【论文阅读】《DCGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bseuoj1j318g0p0afy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《DCGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ADCGAN%E3%80%8B/" title="【论文阅读】《DCGAN》">【论文阅读】《DCGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-28T02:38:13.000Z" title="发表于 2020-08-28 10:38:13">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content">
论文：《UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL
GENERATIVE ADVERSARIAL NETWORKS》
发表日期：ICLR 2016

 前言
这几年CNNs在计算机视觉应用的监督学习方面的应用广泛，而在非监督学习方向的应用就相对没有受到关注。因此，提出的这一深度卷积生成对抗网络（DCGANs）中使用了CNNs的内容，证明它也是可以进行非监督学习的。
通过各类的图像数据训练表明，DCGAN的生成器和鉴别器能够学习从物体部分到场景的表示层次。并且能把学到的特征用于新的任务中，以证明他们可以作为一般图像表征的适用性。
其次，GANs在训练时是不稳定的，经常导致生成器输出没有意义的图片。
 架构设计规则
为了GAN能够很好得适应于卷积神经网络架构，DCGAN提出了四点架构设计规则：

使用卷积层替换池化层
去除全连接层
使用批归一化
使用恰当的激活函数

 卷积层替换池化层
传统的CNN结构不仅包含卷积层，还包括了池化层。而在DCGAN结构中，采取把传统卷积网络中的池化层全部去除的操作，并使用卷积层 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AcGAN%E3%80%8B/" title="【论文阅读】《cGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bpoauw1j318g0p0tfs.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《cGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AcGAN%E3%80%8B/" title="【论文阅读】《cGAN》">【论文阅读】《cGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-28T02:36:20.000Z" title="发表于 2020-08-28 10:36:20">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E7%AE%80%E5%8D%95/">简单</a></span></div><div class="content">
论文：《Conditional Generative Adversarial Nets》
年份：2014年

 引言
原始的GAN过于自由，训练会很容易失去方向，导致不稳定且效果差。比如说GAN生成MNIST数字的过程，虽然可以生成数字，但生成的结果是随机的（因为是根据输入的随机噪声生成的图片），没有办法控制模型生成的具体数字。
CGAN就是在原来的GAN模型中加入一些先验条件，使得GAN变得更加可控制。具体来说，我们可以在生成模型G和判别模型D中同时加入条件约束y来引导数据的生成过程。条件可以是任何补充的信息，如类标签等，这样我们在生成新的样本的同时，还能确切地控制新样本的类型。
 cGAN结构
cGAN的全程是Conditional Generative Adversarial Networks，即条件对抗生成网络。它为生成器、判别器都额外加入了一个条件y，这个条件实际上是希望生成的标签。
生成器G必须要生成和条件y匹配的样本，判别器不仅要判别图像是否真实，还要判别图像和条件y是否匹配。cGAN的输入输出为：

生成器G：输入一个噪声z，一个条件y，输出符合该条件的图像G。
判别 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ACycleGAN%E3%80%8B/" title="【论文阅读】《CycleGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bnm0kjvj318g0p047b.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《CycleGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ACycleGAN%E3%80%8B/" title="【论文阅读】《CycleGAN》">【论文阅读】《CycleGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-28T02:33:48.000Z" title="发表于 2020-08-28 10:33:48">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 摘要
GAN的训练需要图片是两两匹配的，这样经过训练后，生成器可以逐步生成一张让判别期无法判断真伪的图片。但实际上会碰到一些非匹配的图片，于是就提出了非匹配的图片转换(Unpaired image-to-image)，一种在没有成对例子的情况下学习将图像从源域X转换到目标域Y的方法。使得
x→G(x)→F(G(x))≈xx \rightarrow G(x) \rightarrow F(G(x)) \approx x
x→G(x)→F(G(x))≈x
其中xxx是原图，G(x)G(x)G(x)是经过生成器处理后的转换图片，再经过生成器FFF的还原后，还原图片需要尽可能的和原图相同。
 相关工作

GANs
匹配与非匹配的图片转换
一致性损失计算
风格迁移

 系统阐述

目标：找到合适的函数F和G，使得原图和转换后的图片尽可能相似。
结构：由两组生成对抗网络组成；第一组生成对抗网络有生成器GGG（实现G:X→YG: X \rightarrow YG:X→Y的映射）和鉴别器DyD_yDy​（判别图像是目标图片还是转换图片）；第二组生成对抗网络有生成器FFF（实现F:Y→XF: Y \ri ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E9%9D%9E%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E3%80%8B/" title="【论文阅读】《基于对抗一致性的非匹配图像转换》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bjoxvaxj30k00ciwee.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《基于对抗一致性的非匹配图像转换》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E9%9D%9E%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E3%80%8B/" title="【论文阅读】《基于对抗一致性的非匹配图像转换》">【论文阅读】《基于对抗一致性的非匹配图像转换》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-28T02:29:52.000Z" title="发表于 2020-08-28 10:29:52">2020-08-28</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 前言
在CycleGAN中，它最大的问题在于它要求从目标域转换回来的图像要包含原图的所有信息，而这对于很多任务是不现实的。
比如让我们替一张照片中的人添加一副眼镜，显然眼镜类型是多种多样的，因此最终的添加结果也可能是多种多样的，对于生成器也是如此。再比如性别转换时胡须、头发的变化等等，这类问题都具有不可逆的特性。
因此，当使用CycleGAN为图片中的人摘除眼镜的时候，循环一致性损失（Cycle Consistency Loss）尝试解决此问题时，就必须“作弊”在图片中留下痕迹或减小变化，使得转换回去的图片包含原图的信息，但这也就导致了结果的不真实。
如下图所示，使用CycleGAN处理的图片，眼睛周围的颜色有明显不同或者是眉毛处仍有眼镜的痕迹。

因此，根据这一缺点，作者提出了反向一致性损失（Adversarial Consistency Loss，ACL），目标是使目标域和源域共享的信息最大化，而不是严格保持一致。所以，一致性的丢失可以促使生成的图像从分布的角度包含更多源图像的特征。也就是说，被翻译回来的图像只需要与输入源图像相似，而不需要与特定的源图像相同。
因此，我们的生成器 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/28/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/" title="【图像处理】图像金字塔">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bech71uj318g0p0q6u.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【图像处理】图像金字塔"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94/" title="【图像处理】图像金字塔">【图像处理】图像金字塔</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-28T02:23:29.000Z" title="发表于 2020-08-28 10:23:29">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/openCV/">openCV</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E7%AE%80%E5%8D%95/">简单</a></span></div><div class="content"> 前言
图像金字塔是由一幅图像的多个不同分辨率的子图所构成的图像集合。该组图像是由单个图像通过不断地降采样所产生的，最小的图像可能仅仅有一个像素点。

由此看出，图像金字塔就是一系列以金字塔形状排列的、自底向上分辨率逐渐降低的图像集合。
通常情况下，图像金字塔的底部是待处理的高分辨率图像（原始图像），而顶部则为其低分辨率的近似图像。向金字塔的顶部移动时，图像的尺寸和分辨率都不断地降低。
一般每向上移动一级，图像的宽和高都降低为原来的二分之一。
高斯金字塔是通过对一幅图像不断的向下采样所产生的，如果对金字塔中的小图像进行向上采样以获取完整的大尺寸高分辨率图像，这时就需要用到拉普拉斯金字塔。
 高斯金字塔

上采样：每次的长和高都降低为原来的两倍，但实际的分辨率是会变低的。
下采样：图片由高分辨率到低分辨率，每次的宽和高都降低为原来的二分之一。

 下采样
得到某张高分辨率图片的图像金字塔有两种方式：
方法一：直接通过不断地删除图像的偶数行和偶数列得到。例如，有一幅图像，其大小是N x N，删除其偶数行和偶数列后得到一幅(N/2) x (N/2)大小的图像。经过上述处理后，图像大小变为原来 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/25/%E3%80%90%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%E3%80%91%E5%B9%B6%E6%9F%A5%E9%9B%86/" title="【算法专题】并查集">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi2cr5vgqgj30k00cimxj.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【算法专题】并查集"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/25/%E3%80%90%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%E3%80%91%E5%B9%B6%E6%9F%A5%E9%9B%86/" title="【算法专题】并查集">【算法专题】并查集</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2020-08-24T16:09:22.000Z" title="发表于 2020-08-25 00:09:22">2020-08-25</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/%E5%B9%B6%E6%9F%A5%E9%9B%86/">并查集</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 集合专题
 初始化parent集合
123456const int N = 100;int parent[N], rank[N];for(int i = 0; i &lt; N; i++) &#123;  parent[i] = i;  rank[i] = 0; // 为路径压缩做准备&#125;
 寻找祖先结点
12345int find(int parent[], int x) &#123;  if(parent[x] != x) x = parent[x]; find(parent, x);  return x;  // 不管祖先是不是自己 都是返回的x&#125;
 合并集合
1234567891011121314void Union(int parent[], int x, int y) &#123;  int xp = find(parent, x);  int yp = find(parent, y);  if(xp != yp) parent[xp] = yp; // x 并入 y  // 反之则表明两者在同一个集合之中 不进行其他操作  // 路径压缩如下  /** ...</div></div></div><nav id="pagination"><div class="pagination"><span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghwjow3dndj30jg0jgdgq.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Sonata</div><div class="author-info__description">佳期不可再，风雨杳如年</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives"><div class="headline">文章</div><div class="length_num">24</div></a></div><div class="card-info-data-item is-center">      <a href="/tags"><div class="headline">标签</div><div class="length_num">3</div></a></div><div class="card-info-data-item is-center"><a href="/categories"><div class="headline">分类</div><div class="length_num">14</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">做一个认真的学习者</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-recent-item"><div class="aside-recent-post"><a class="aside-post-cover" href="/2020/08/29/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="【机器学习】K近邻算法原理与实践"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi80z5ja2uj31hc0u0ag1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】K近邻算法原理与实践"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2020/08/29/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="【机器学习】K近邻算法原理与实践">【机器学习】K近邻算法原理与实践</a><time class="aside-post_meta post-meta-date" datetime="2020-08-29T13:55:16.000Z" title="发表于 2020-08-29 21:55:16">2020-08-29</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2020/08/29/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93/" title="【图像处理】图像轮廓"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi7jwhy37fj31de0rs4fs.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【图像处理】图像轮廓"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2020/08/29/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93/" title="【图像处理】图像轮廓">【图像处理】图像轮廓</a><time class="aside-post_meta post-meta-date" datetime="2020-08-29T04:02:32.000Z" title="发表于 2020-08-29 12:02:32">2020-08-29</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/" title="【论文阅读】《StarGAN》"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bwff3axj318g0p0ac5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《StarGAN》"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/" title="【论文阅读】《StarGAN》">【论文阅读】《StarGAN》</a><time class="aside-post_meta post-meta-date" datetime="2020-08-28T02:42:42.000Z" title="发表于 2020-08-28 10:42:42">2020-08-28</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8APix2Pix%E3%80%8B/" title="【论文阅读】《Pix2Pix》"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bthvkq1j315o0mzwj5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《Pix2Pix》"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8APix2Pix%E3%80%8B/" title="【论文阅读】《Pix2Pix》">【论文阅读】《Pix2Pix》</a><time class="aside-post_meta post-meta-date" datetime="2020-08-28T02:41:18.000Z" title="发表于 2020-08-28 10:41:18">2020-08-28</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ADCGAN%E3%80%8B/" title="【论文阅读】《DCGAN》"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bseuoj1j318g0p0afy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《DCGAN》"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ADCGAN%E3%80%8B/" title="【论文阅读】《DCGAN》">【论文阅读】《DCGAN》</a><time class="aside-post_meta post-meta-date" datetime="2020-08-28T02:38:13.000Z" title="发表于 2020-08-28 10:38:13">2020-08-28</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>分类</span></div><ul class="card-category-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="card-category-list-name">图像处理</span><span class="card-category-list-count">7</span></a></li><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/openCV/"><span class="card-category-list-name">openCV</span><span class="card-category-list-count">7</span></a></li></ul><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"><span class="card-category-list-name">数据分析</span><span class="card-category-list-count">3</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">机器学习</span><span class="card-category-list-count">1</span></a></li><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/"><span class="card-category-list-name">算法原理</span><span class="card-category-list-count">1</span></a></li></ul><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">深度学习</span><span class="card-category-list-count">2</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%AE%97%E6%B3%95/"><span class="card-category-list-name">算法</span><span class="card-category-list-count">5</span></a></li><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E7%AE%97%E6%B3%95/%E5%9B%BE%E8%AE%BA/"><span class="card-category-list-name">图论</span><span class="card-category-list-count">1</span></a></li></ul>
            <li class="card-category-list-item more is-center"><a class="card-category-list-link-more" href="/categories">
                <span>查看更多</span><i class="fas fa-angle-right"></i></a></li>           
            </ul></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>标签</span></div><div class="card-tag-cloud"><a href="/tags/%E4%B8%AD%E7%AD%89/" style="font-size: 22px; color: #99a9bf">中等</a> <a href="/tags/%E5%9B%B0%E9%9A%BE/" style="font-size: 16px; color: #999">困难</a> <a href="/tags/%E7%AE%80%E5%8D%95/" style="font-size: 19px; color: #99a1ac">简单</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2020/08/"><span class="card-archive-list-date">八月 2020</span><span class="card-archive-list-count">24</span></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>网站资讯</span></div><div class="webinfo"><div class="webinfo-item"><div class="webinfo-article-name">文章数目 :</div><div class="webinfo-article-count">24</div></div><div class="webinfo-item">      <div class="webinfo-site-uv-name">本站访客数 :</div><div class="webinfo-site-uv-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="webinfo-site-name">本站总访问量 :</div><div class="webinfo-site-pv-count" id="busuanzi_value_site_pv"></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://tva1.sinaimg.cn/large/007S8ZIlly1ghwkr89vbaj31hc0u0ag1.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 By Sonata</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">hi there ~</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/third-party/click_heart.js" async="async"></script></div></body></html>