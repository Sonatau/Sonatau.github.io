<!DOCTYPE html><html lang="default" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>私人海域</title><meta name="description" content="温和安静 爱我所爱"><meta name="keywords" content="test"><meta name="author" content="Sonata,sonatau@163.com"><meta name="copyright" content="Sonata"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://tva1.sinaimg.cn/large/008i3skNly1gwehay3b55j305k05k74a.jpg"><link rel="canonical" href="http://yluy.gitee.io/page/7/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="website"><meta property="og:title" content="私人海域"><meta property="og:url" content="http://yluy.gitee.io/page/7/"><meta property="og:site_name" content="私人海域"><meta property="og:description" content="温和安静 爱我所爱"><meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gweh81b6pyj30u00u0q49.jpg"><meta property="article:published_time" content="2023-07-31T06:47:00.698Z"><meta property="article:modified_time" content="2023-07-31T06:47:00.698Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.0.2',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  bookmark: {
    message_prev: 'Press',
    message_next: 'to bookmark this page'
  },
  runtime_unit: 'days',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: false,
  isHome: true,
  isHighlightShrink: false,
  isSidebar: false,
  postUpdate: '2023-07-31 14:47:00'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 5.0.2"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="https://tva1.sinaimg.cn/large/008i3skNly1gweh81b6pyj30u00u0q49.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">86</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">Tags</div><div class="length_num">15</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">Categories</div><div class="length_num">25</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Homepage</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tag</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></div></div></div></div><div id="body-wrap"><header class="full_page" id="page-header" style="background-image: url(https://tva1.sinaimg.cn/large/008i3skNly1gw49zfypmwj31h70u04a1.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">私人海域</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Homepage</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archive</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tag</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Category</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="site-info"><h1 id="site_title">私人海域</h1><div id="site_subtitle"><span id="subtitle"></span></div></div><div id="scroll_down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout_page" id="content-inner"><div class="recent-posts" id="recent-posts"><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/09/09/%E3%80%90%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%E3%80%91%E4%BA%8C%E5%8F%89%E6%A0%91/" title="【算法专题】二叉树">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gik8gm13agj30qe0f0gnb.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【算法专题】二叉树"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/09/09/%E3%80%90%E7%AE%97%E6%B3%95%E4%B8%93%E9%A2%98%E3%80%91%E4%BA%8C%E5%8F%89%E6%A0%91/" title="【算法专题】二叉树">【算法专题】二叉树</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-09-09T03:21:09.000Z" title="Created 2020-09-09 11:21:09">2020-09-09</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/">算法</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E7%AE%97%E6%B3%95/%E4%BA%8C%E5%8F%89%E6%A0%91/">二叉树</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 二叉树
 构建二叉树
123456789101112131415161718192021typedef struct BTNode&#123;  int data;  struct BTNode *left;  struct BTNode *right;&#125;BTNode;// 创建二叉树BTNode BinaryTree() &#123;  BTNode *T = (BTNode*)malloc(sizeof(BTNode));  T-&gt;data = 0;  return T;&#125;//BinaryEmpty(T):bool 判断树是否为空//Root(T):int 返回根结点data//构造二叉树BTNode MakeTree(int x, BTNode *l, BTNode *r) &#123;  BTNode *T = (BTNode*)malloc(sizeof(BTNode));  T-&gt;data = x;  T-&gt;left = l; T-&gt;right = r;  return T;&#125;//BreakTree(x,T,l,r): ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/09/06/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" title="【机器学习】朴素贝叶斯算法原理">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gigt1aoj71j30jg0el401.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】朴素贝叶斯算法原理"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/09/06/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/" title="【机器学习】朴素贝叶斯算法原理">【机器学习】朴素贝叶斯算法原理</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-09-06T04:00:16.000Z" title="Created 2020-09-06 12:00:16">2020-09-06</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/">算法原理</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E7%AE%80%E5%8D%95/">简单</a></span></div><div class="content"> 朴素贝叶斯法的学习与分类
 先验概率


反映了我们在实际观察之前对某种状态的预期。绝大多数情况下，是根据过去的观测统计得到的数据计算可能性。且所有可能性概率之和为1。
例如，投掷硬币1000次，进行多个回合后的测试可发现，有1/2的概率丢到正面，1/2的概率成为反面。因此，可以说得到正面或得到反面的先验概率是 1/2 的。


正常情况下，可以基于先验做出决策。
例如，统计北京的天气情况可以发现，一年中近乎80%的时间天气是晴朗无雨的，那么在判断是否进行某种运动时，则可以根据此概率确定。


直接使用先验概率的局限很大。
它在不同的时间段内总是做出同样的预测，这是极其不适用的；例如，预测同一年龄段的老年人是否有高血压时，不能单靠先验概率进行直接判断，而是需要考虑到个人的家庭因素、作息等情况。
其次，它无法利用现有的信息进行决策。
最后，如果先验概率是均匀的，那么规则效果不佳。例如，在投掷硬币时，正反面的概率均为1/2，对下一次的投掷结果进行预测，就没有任何的优势，基本是靠猜测。


解决办法：引入特征。可以引入多个观测变量，形成一个特征空间，即进行观测值采样的空间。借助这些观测变量 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/29/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="【机器学习】K近邻算法原理与实践">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi80z5ja2uj31hc0u0ag1.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】K近邻算法原理与实践"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/29/%E3%80%90%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E3%80%91K%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5/" title="【机器学习】K近邻算法原理与实践">【机器学习】K近邻算法原理与实践</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-29T13:55:16.000Z" title="Created 2020-08-29 21:55:16">2020-08-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95%E5%8E%9F%E7%90%86/">算法原理</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 前言
KNN（K-k-nearest neighbors）又叫做K近邻，是机器学习中相对简单好理解的算法，并且它是唯一一个不需要训练就可以得到预测结果的模型。
我们常说物以类聚，人以群分，大家之所以能够成为朋友，多少是因为身上的某些特质是相近的，K近邻算法借助的就是这个思想。它使用某种方法找到样本空间中距离测试点最近的K个点，以投票表决的方式决定该测试点的标签。
本文将结合阿里云提供的机器学习算法(三): K近邻(k-nearest neighbors)初探与清华大学李航老师的PPT，来具体解释这其中的理论基础和代码实例。
 KNN理论基础
 背景介绍
大家通过视频软件挑选电影的时候，通常会先按照电影的类别进行挑选，例如动作片、爱情片、歌舞片。这些电影有各自的特点，像是动作片的打斗场景一定比爱情片多，它也不会像音乐片一样一言不合就开始跳舞，但又不能完全排除有出现的可能。
总结这三类型的影片所具有的显著特点：打斗、亲吻、跳舞。假设现在用一个元组(a, b, c)来表示，值在0～1之间，Movie = (0.8, 0.1, 0.1)时，就认为这个电影是动作片。那么很自然的，提出了使用一个 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/29/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93/" title="【图像处理】图像轮廓">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi7jwhy37fj31de0rs4fs.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【图像处理】图像轮廓"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/29/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93/" title="【图像处理】图像轮廓">【图像处理】图像轮廓</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-29T04:02:32.000Z" title="Created 2020-08-29 12:02:32">2020-08-29</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/openCV/">openCV</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E7%AE%80%E5%8D%95/">简单</a></span></div><div class="content">openCV中可以使用一些函数找到图像轮廓，进而获取目标图像的大小、位置、方向等信息。
下面将针对下图来做图像轮廓的说明：

 查找图像轮廓findCounters
1contours, hierarchy = cv2.findContours( image, mode, method)
式中的返回值为：

contours：返回的轮廓。
hierarchy：图像的拓扑信息（轮廓层次）。

式中的参数为：

image：原始图像。8位单通道图像，所有非零值被处理为1，所有零值保持不变。也就是说灰度图像会被自动处理为二值图像。在实际操作时，可以根据需要，预先使用阈值处理等函数将待查找轮廓的图像处理为二值图像。
mode：轮廓检索模式。
method：轮廓的近似方法。

函数cv2.findContours()的返回值及参数的含义比较丰富，下面对上述返回值和参数逐一做出说明。
 返回值contours
该返回值返回的是一组轮廓信息，类型为list，每个轮廓都是由若干个点所构成的。

coutours[i][j]表示的是第i个轮廓内的第j个点。
len(contours)的结果表示图中找到了 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/" title="【论文阅读】《StarGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bwff3axj318g0p0ac5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《StarGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/" title="【论文阅读】《StarGAN》">【论文阅读】《StarGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-28T02:42:42.000Z" title="Created 2020-08-28 10:42:42">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content">
论文：《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》
发表时间：CVPR 2018
解决问题：多领域的图像转换问题

 背景
Pix2Pix与CycleGAN分别解决了两个领域之间基于匹配数据和非匹配数据的转换。但是在实际的应用中我们会发现需要大量的多领域转换，例如图1所示，这可能是一个智能修图的场景，用户输入一张人物照片，他希望能够通过选项来调节照片中人物的外貌，比如图中例子的发色、性别、年龄、肤色等。又比如图2，对于同一个人物照片我们希望能够将他转换成各种不一样的表情，从普通的表情转换为愤怒、喜悦和恐惧等。


之前的Pix2Pix和CycleGAN可以非常好地解决领域间转换问题，它们同样可以应用于多领域的转换，但是存在的问题是必须在每两个领域之间进行单独的训练。我们假设场景为图8-3的表情转换，一共有四个领域，分别为中性、生气、喜悦与恐惧，我们将它们从1到4标号。如果使用CycleGAN的话我们可以看到图3，在每两个领域都需要训练两个生成 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8APix2Pix%E3%80%8B/" title="【论文阅读】《Pix2Pix》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bthvkq1j315o0mzwj5.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《Pix2Pix》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8APix2Pix%E3%80%8B/" title="【论文阅读】《Pix2Pix》">【论文阅读】《Pix2Pix》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-28T02:41:18.000Z" title="Created 2020-08-28 10:41:18">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content">
论文：《Image-to-Image Translation with Conditional Adversarial Networks》
发表日期：2017 CVPR

 前言
pix2pix是cGAN的一个变体，能够实现从图像到图像的映射，在从标签映射合成照片、从边缘映射重建对象、图片上色等多类人物的表现较好。它比较适合于监督学习，即图像的输入和它的输出是相互匹配的。所谓匹配数据集是指在训练集中两个互相转换的领域之间有明确的一一对应数据。在工程实践中研究者需要自己收集这些匹配数据，但有时同时采集两个不同领域的匹配数据是麻烦的，通常采用的方案是从更完整的数据中还原简单数据。比如直接将彩色图片通过图像处理的方法转为黑白图片。
训练完成后，pix2pix可以将图像从领域A变换到领域B。下面这张图中，左侧的input和output分别是同一个地方白天和夜晚的照片，看作是不同领域X和Y的两张图，生成器G应尽可能得将input转换成output。

注意，因为匹配数据集的存在，研究者尝试用普通CNN进行图像对图像的变换，但是不能生成清晰逼真的图像，因为CNN会试图让最终的输出接近所有相类似的 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ADCGAN%E3%80%8B/" title="【论文阅读】《DCGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bseuoj1j318g0p0afy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《DCGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ADCGAN%E3%80%8B/" title="【论文阅读】《DCGAN》">【论文阅读】《DCGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-28T02:38:13.000Z" title="Created 2020-08-28 10:38:13">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content">
论文：《UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL
GENERATIVE ADVERSARIAL NETWORKS》
发表日期：ICLR 2016

 前言
这几年CNNs在计算机视觉应用的监督学习方面的应用广泛，而在非监督学习方向的应用就相对没有受到关注。因此，提出的这一深度卷积生成对抗网络（DCGANs）中使用了CNNs的内容，证明它也是可以进行非监督学习的。
通过各类的图像数据训练表明，DCGAN的生成器和鉴别器能够学习从物体部分到场景的表示层次。并且能把学到的特征用于新的任务中，以证明他们可以作为一般图像表征的适用性。
其次，GANs在训练时是不稳定的，经常导致生成器输出没有意义的图片。
 架构设计规则
为了GAN能够很好得适应于卷积神经网络架构，DCGAN提出了四点架构设计规则：

使用卷积层替换池化层
去除全连接层
使用批归一化
使用恰当的激活函数

 卷积层替换池化层
传统的CNN结构不仅包含卷积层，还包括了池化层。而在DCGAN结构中，采取把传统卷积网络中的池化层全部去除的操作，并使用卷积层 ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AcGAN%E3%80%8B/" title="【论文阅读】《cGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bpoauw1j318g0p0tfs.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《cGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AcGAN%E3%80%8B/" title="【论文阅读】《cGAN》">【论文阅读】《cGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-28T02:36:20.000Z" title="Created 2020-08-28 10:36:20">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E7%AE%80%E5%8D%95/">简单</a></span></div><div class="content">
论文：《Conditional Generative Adversarial Nets》
年份：2014年

 引言
原始的GAN过于自由，训练会很容易失去方向，导致不稳定且效果差。比如说GAN生成MNIST数字的过程，虽然可以生成数字，但生成的结果是随机的（因为是根据输入的随机噪声生成的图片），没有办法控制模型生成的具体数字。
CGAN就是在原来的GAN模型中加入一些先验条件，使得GAN变得更加可控制。具体来说，我们可以在生成模型G和判别模型D中同时加入条件约束y来引导数据的生成过程。条件可以是任何补充的信息，如类标签等，这样我们在生成新的样本的同时，还能确切地控制新样本的类型。
 cGAN结构
cGAN的全程是Conditional Generative Adversarial Networks，即条件对抗生成网络。它为生成器、判别器都额外加入了一个条件y，这个条件实际上是希望生成的标签。
生成器G必须要生成和条件y匹配的样本，判别器不仅要判别图像是否真实，还要判别图像和条件y是否匹配。cGAN的输入输出为：

生成器G：输入一个噪声z，一个条件y，输出符合该条件的图像G。
判别 ...</div></div></div><div class="recent-post-item"><div class="post_cover left_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ACycleGAN%E3%80%8B/" title="【论文阅读】《CycleGAN》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bnm0kjvj318g0p047b.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《CycleGAN》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8ACycleGAN%E3%80%8B/" title="【论文阅读】《CycleGAN》">【论文阅读】《CycleGAN》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-28T02:33:48.000Z" title="Created 2020-08-28 10:33:48">2020-08-28</time></span><span class="article-meta"><span class="article-meta__separator">|</span><i class="fas fa-inbox article-meta__icon"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right"></i><a class="article-meta__categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 摘要
GAN的训练需要图片是两两匹配的，这样经过训练后，生成器可以逐步生成一张让判别期无法判断真伪的图片。但实际上会碰到一些非匹配的图片，于是就提出了非匹配的图片转换(Unpaired image-to-image)，一种在没有成对例子的情况下学习将图像从源域X转换到目标域Y的方法。使得
x→G(x)→F(G(x))≈xx \rightarrow G(x) \rightarrow F(G(x)) \approx x
x→G(x)→F(G(x))≈x
其中xxx是原图，G(x)G(x)G(x)是经过生成器处理后的转换图片，再经过生成器FFF的还原后，还原图片需要尽可能的和原图相同。
 相关工作

GANs
匹配与非匹配的图片转换
一致性损失计算
风格迁移

 系统阐述

目标：找到合适的函数F和G，使得原图和转换后的图片尽可能相似。
结构：由两组生成对抗网络组成；第一组生成对抗网络有生成器GGG（实现G:X→YG: X \rightarrow YG:X→Y的映射）和鉴别器DyD_yDy​（判别图像是目标图片还是转换图片）；第二组生成对抗网络有生成器FFF（实现F:Y→XF: Y \ri ...</div></div></div><div class="recent-post-item"><div class="post_cover right_radius"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E9%9D%9E%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E3%80%8B/" title="【论文阅读】《基于对抗一致性的非匹配图像转换》">     <img class="post_bg" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bjoxvaxj30k00ciwee.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】《基于对抗一致性的非匹配图像转换》"></a></div><div class="recent-post-info"><a class="article-title" href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8A%E5%9F%BA%E4%BA%8E%E5%AF%B9%E6%8A%97%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E9%9D%9E%E5%8C%B9%E9%85%8D%E5%9B%BE%E5%83%8F%E8%BD%AC%E6%8D%A2%E3%80%8B/" title="【论文阅读】《基于对抗一致性的非匹配图像转换》">【论文阅读】《基于对抗一致性的非匹配图像转换》</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">Created</span><time datetime="2020-08-28T02:29:52.000Z" title="Created 2020-08-28 10:29:52">2020-08-28</time></span><span class="article-meta tags"><span class="article-meta__separator">|</span><i class="fas fa-tag article-meta__icon"></i><a class="article-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></span></div><div class="content"> 前言
在CycleGAN中，它最大的问题在于它要求从目标域转换回来的图像要包含原图的所有信息，而这对于很多任务是不现实的。
比如让我们替一张照片中的人添加一副眼镜，显然眼镜类型是多种多样的，因此最终的添加结果也可能是多种多样的，对于生成器也是如此。再比如性别转换时胡须、头发的变化等等，这类问题都具有不可逆的特性。
因此，当使用CycleGAN为图片中的人摘除眼镜的时候，循环一致性损失（Cycle Consistency Loss）尝试解决此问题时，就必须“作弊”在图片中留下痕迹或减小变化，使得转换回去的图片包含原图的信息，但这也就导致了结果的不真实。
如下图所示，使用CycleGAN处理的图片，眼睛周围的颜色有明显不同或者是眉毛处仍有眼镜的痕迹。

因此，根据这一缺点，作者提出了反向一致性损失（Adversarial Consistency Loss，ACL），目标是使目标域和源域共享的信息最大化，而不是严格保持一致。所以，一致性的丢失可以促使生成的图像从分布的角度包含更多源图像的特征。也就是说，被翻译回来的图像只需要与输入源图像相似，而不需要与特定的源图像相同。
因此，我们的生成器 ...</div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/6/"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><a class="extend next" rel="next" href="/page/8/"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div><div class="aside_content" id="aside_content"><div class="card-widget card-info"><div class="card-content"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="https://tva1.sinaimg.cn/large/008i3skNly1gweh81b6pyj30u00u0q49.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Sonata</div><div class="author-info__description">温和安静</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives"><div class="headline">Articles</div><div class="length_num">86</div></a></div><div class="card-info-data-item is-center">      <a href="/tags"><div class="headline">Tags</div><div class="length_num">15</div></a></div><div class="card-info-data-item is-center"><a href="/categories"><div class="headline">Categories</div><div class="length_num">25</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Sonatau"><i class="fab fa-github"></i><span>Follow Me</span></a></div></div><div class="card-widget card-announcement"><div class="card-content"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>Announcement</span></div><div class="announcement_content">做一事有一事的收获，过一日有一日的长进</div></div></div><div class="card-widget card-recent-post"><div class="card-content"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-recent-item"><div class="aside-recent-post"><a class="aside-post-cover" href="/2022/03/14/Javascript%E4%BD%9C%E7%94%A8%E5%9F%9F%E4%B8%8E%E9%97%AD%E5%8C%85/" title="Javascript作用域与闭包"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/e6c9d24ely1h09a1nnu4hj20u00u00vy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Javascript作用域与闭包"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2022/03/14/Javascript%E4%BD%9C%E7%94%A8%E5%9F%9F%E4%B8%8E%E9%97%AD%E5%8C%85/" title="Javascript作用域与闭包">Javascript作用域与闭包</a><time class="aside-post_meta post-meta-date" datetime="2022-03-14T04:01:38.000Z" title="Created 2022-03-14 12:01:38">2022-03-14</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2022/03/14/Javascript%E5%8E%9F%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%9E%8B%E9%93%BE/" title="Javascript原型与原型链"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/e6c9d24ely1h099znlnfyj20u00u0402.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Javascript原型与原型链"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2022/03/14/Javascript%E5%8E%9F%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%9E%8B%E9%93%BE/" title="Javascript原型与原型链">Javascript原型与原型链</a><time class="aside-post_meta post-meta-date" datetime="2022-03-14T03:59:39.000Z" title="Created 2022-03-14 11:59:39">2022-03-14</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2022/03/14/Javascript%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/" title="Javascript异步编程"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/e6c9d24ely1h099x5m7t3j20u00u0dis.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Javascript异步编程"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2022/03/14/Javascript%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/" title="Javascript异步编程">Javascript异步编程</a><time class="aside-post_meta post-meta-date" datetime="2022-03-14T03:55:11.000Z" title="Created 2022-03-14 11:55:11">2022-03-14</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2021/12/17/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/" title="决策树笔记"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/008i3skNly1gxh4h3d94bj31940u0tig.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="决策树笔记"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2021/12/17/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/" title="决策树笔记">决策树笔记</a><time class="aside-post_meta post-meta-date" datetime="2021-12-17T12:48:40.000Z" title="Created 2021-12-17 20:48:40">2021-12-17</time></div></div><div class="aside-recent-post"><a class="aside-post-cover" href="/2021/12/02/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E8%A7%A3%E8%AF%BB/" title="模型评估指标解读"><img class="aside-post-bg" data-lazy-src="https://tva1.sinaimg.cn/large/008i3skNly1gwzb8rx004j31hg0u0dtv.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="模型评估指标解读"/></a><div class="aside-post-info"><a class="aside-post-title" href="/2021/12/02/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E8%A7%A3%E8%AF%BB/" title="模型评估指标解读">模型评估指标解读</a><time class="aside-post_meta post-meta-date" datetime="2021-12-02T03:02:15.000Z" title="Created 2021-12-02 11:02:15">2021-12-02</time></div></div></div></div></div><div class="card-widget card-categories"><div class="card-content"><div class="item-headline"><i class="fas fa-folder-open"></i><span>Categories</span></div><ul class="card-category-list">
            <li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%89%8D%E7%AB%AF/"><span class="card-category-list-name">前端</span><span class="card-category-list-count">3</span></a></li><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%89%8D%E7%AB%AF/JavaScript/"><span class="card-category-list-name">JavaScript</span><span class="card-category-list-count">3</span></a></li></ul><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"><span class="card-category-list-name">图像处理</span><span class="card-category-list-count">10</span></a></li><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/openCV/"><span class="card-category-list-name">openCV</span><span class="card-category-list-count">8</span></a></li></ul><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"><span class="card-category-list-name">数据分析</span><span class="card-category-list-count">4</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="card-category-list-name">数据库</span><span class="card-category-list-count">1</span></a></li><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="card-category-list-name">机器学习</span><span class="card-category-list-count">10</span></a></li><ul class="card-category-list child"><li class="card-category-list-item "><a class="card-category-list-link" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC/"><span class="card-category-list-name">公式推导</span><span class="card-category-list-count">1</span></a></li></ul>
            <li class="card-category-list-item more is-center"><a class="card-category-list-link-more" href="/categories">
                <span>More</span><i class="fas fa-angle-right"></i></a></li>           
            </ul></div></div><div class="card-widget card-tags"><div class="card-content"><div class="item-headline"><i class="fas fa-tags"></i><span>Tags</span></div><div class="card-tag-cloud"><a href="/tags/CVPR/" style="font-size: 17.2px; color: #999ca1">CVPR</a> <a href="/tags/Colorization/" style="font-size: 19.6px; color: #99a3b0">Colorization</a> <a href="/tags/GAN/" style="font-size: 19.6px; color: #99a3b0">GAN</a> <a href="/tags/Leetcode/" style="font-size: 16px; color: #999">Leetcode</a> <a href="/tags/SIGGRAPH/" style="font-size: 16px; color: #999">SIGGRAPH</a> <a href="/tags/bash/" style="font-size: 16px; color: #999">bash</a> <a href="/tags/todoList/" style="font-size: 16px; color: #999">todoList</a> <a href="/tags/%E4%B8%AD%E7%AD%89/" style="font-size: 22px; color: #99a9bf">中等</a> <a href="/tags/%E5%85%B6%E4%BB%96/" style="font-size: 18.4px; color: #999fa8">其他</a> <a href="/tags/%E5%9B%B0%E9%9A%BE/" style="font-size: 16px; color: #999">困难</a> <a href="/tags/%E5%9B%BE%E5%83%8F%E7%BF%BB%E8%AF%91/" style="font-size: 16px; color: #999">图像翻译</a> <a href="/tags/%E6%96%87%E6%9C%AC%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90/" style="font-size: 16px; color: #999">文本图像生成</a> <a href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" style="font-size: 17.2px; color: #999ca1">神经网络</a> <a href="/tags/%E7%AE%80%E5%8D%95/" style="font-size: 20.8px; color: #99a6b7">简单</a> <a href="/tags/%E8%B5%84%E6%96%99/" style="font-size: 16px; color: #999">资料</a></div></div></div><div class="card-widget card-archives"><div class="card-content"><div class="item-headline"><i class="fas fa-archive"></i><span>Archives</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2022/03/"><span class="card-archive-list-date">March 2022</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/12/"><span class="card-archive-list-date">December 2021</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/11/"><span class="card-archive-list-date">November 2021</span><span class="card-archive-list-count">5</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/09/"><span class="card-archive-list-date">September 2021</span><span class="card-archive-list-count">2</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/08/"><span class="card-archive-list-date">August 2021</span><span class="card-archive-list-count">6</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/07/"><span class="card-archive-list-date">July 2021</span><span class="card-archive-list-count">4</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/06/"><span class="card-archive-list-date">June 2021</span><span class="card-archive-list-count">1</span></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2021/05/"><span class="card-archive-list-date">May 2021</span><span class="card-archive-list-count">3</span></a></li><li class="card-archive-list-item more is-center"><a class="card-archive-list-link-more" href="/archives">
              <span>More</span><i class="fas fa-angle-right"  ></i></a></li></ul></div></div><div class="card-widget card-webinfo"><div class="card-content"><div class="item-headline"><i class="fas fa-chart-line"></i><span>Info</span></div><div class="webinfo"><div class="webinfo-item"><div class="webinfo-article-name">Article :</div><div class="webinfo-article-count">86</div></div><div class="webinfo-item">      <div class="webinfo-site-uv-name">UV :</div><div class="webinfo-site-uv-count" id="busuanzi_value_site_uv"></div></div><div class="webinfo-item"><div class="webinfo-site-name">PV :</div><div class="webinfo-site-pv-count" id="busuanzi_value_site_pv"></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://tva1.sinaimg.cn/large/008i3skNly1gw49zfypmwj31h70u04a1.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Sonata</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">hi there ~</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><div class="js-pjax"><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/third-party/click_heart.js" async="async"></script></div></body></html>