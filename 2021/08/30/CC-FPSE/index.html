<!DOCTYPE html><html lang="default" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>CC-FPSE | 私人海域</title><meta name="author" content="Sonata,sonatau@163.com"><meta name="copyright" content="Sonata"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Title：Learning to Predict Layout-to-image Conditional Convolutions for Semantic Image Synthesis Year：NeurIPS 2019 Author：Xihui Liu School：The Chinese University of HongKong Code：https:&#x2F;&#x2F;github.com&#x2F;xh-">
<meta property="og:type" content="article">
<meta property="og:title" content="CC-FPSE">
<meta property="og:url" content="http://yluy.gitee.io/2021/08/30/CC-FPSE/index.html">
<meta property="og:site_name" content="私人海域">
<meta property="og:description" content="Title：Learning to Predict Layout-to-image Conditional Convolutions for Semantic Image Synthesis Year：NeurIPS 2019 Author：Xihui Liu School：The Chinese University of HongKong Code：https:&#x2F;&#x2F;github.com&#x2F;xh-">
<meta property="og:locale">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gtysla6wewj60rs0rsq8y02.jpg">
<meta property="article:published_time" content="2021-08-30T06:17:09.000Z">
<meta property="article:modified_time" content="2021-08-30T06:21:53.128Z">
<meta property="article:author" content="Sonata">
<meta property="article:tag" content="GAN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/008i3skNly1gtysla6wewj60rs0rsq8y02.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://yluy.gitee.io/2021/08/30/CC-FPSE/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'CC-FPSE',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-08-30 14:21:53'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://tva1.sinaimg.cn/large/008i3skNly1gweh81b6pyj30u00u0q49.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">87</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><hr class="custom-hr"/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://tva1.sinaimg.cn/large/008i3skNly1gtysla6wewj60rs0rsq8y02.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="私人海域"><span class="site-name">私人海域</span></a></span><div id="menus"><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">CC-FPSE</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-08-30T06:17:09.000Z" title="Created 2021-08-30 14:17:09">2021-08-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-08-30T06:21:53.128Z" title="Updated 2021-08-30 14:21:53">2021-08-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="CC-FPSE"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong>Title</strong>：Learning to Predict Layout-to-image Conditional Convolutions for Semantic Image Synthesis<br />
<strong>Year</strong>：NeurIPS 2019<br />
<strong>Author</strong>：Xihui Liu<br />
<strong>School</strong>：The Chinese University of HongKong<br />
<strong>Code</strong>：<a target="_blank" rel="noopener" href="https://github.com/xh-liu/CC-FPSE">https://github.com/xh-liu/CC-FPSE</a></p>
<h2 id="topic-and-gap"><a class="markdownIt-Anchor" href="#topic-and-gap"></a> Topic and Gap</h2>
<h3 id="topic"><a class="markdownIt-Anchor" href="#topic"></a> Topic</h3>
<p>Semantic image synthesis, which aims at generating photorealistic images conditioned on semantic layouts.</p>
<h3 id="gap"><a class="markdownIt-Anchor" href="#gap"></a> Gap</h3>
<p><strong>How to exploit the semantic layout information in the generator</strong></p>
<ul>
<li>Preserve information: most of network just be fed into semantic label maps once at the input layers.</li>
<li>Spatial locations: distinct semantic labels at different locations as well as the unique semantic layout of each sample, different convolutional kernels should be used for generating different stuff or object.</li>
</ul>
<p><strong>How to promote high-fidelity details and enhance the spatial semantic alignment in the discriminator</strong></p>
<ul>
<li>High-fidelity details includes texture and edges</li>
<li>the spatial semantic alignment between generated image and semantic label layout</li>
<li>Current discriminator seems without considering whether generated image matches well with the label map.</li>
</ul>
<h2 id="contributions"><a class="markdownIt-Anchor" href="#contributions"></a> Contributions</h2>
<ul>
<li>Predict layout-to-image conditional convolution kernels based on the semantic layout for generating.</li>
<li>A feature pyramid semantics-embedding discriminator.</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gtym3qrstlj616q0j610q02.jpg" alt="" /></p>
<h2 id="method-details"><a class="markdownIt-Anchor" href="#method-details"></a> Method Details</h2>
<h3 id="image-generation"><a class="markdownIt-Anchor" href="#image-generation"></a> Image Generation</h3>
<p><strong>Model input</strong></p>
<ul>
<li>Noise Map with CC kernels from Weight Prediction Network</li>
</ul>
<p><strong>Kernel weight</strong><br />
For traditional convolution layers, they are applied to all samples and at all spatial locations, but different objects should be generated differently, the better way is, at each convolution layers and each multiplication times, these kernels weights are suitable for that locations, by given semantic label map.</p>
<p><strong>Depthwise separable convolution</strong><br />
In order to avoid excessive computational costs and GPU memory usage, the author uses “depthwise separable convolution” to predict weights for each layer.</p>
<ul>
<li><u>definition</u>: The depth wise separable convolutions consist of two steps: depthwise convolutions and 1x1 convolutions.</li>
<li><u>info details</u>: <a target="_blank" rel="noopener" href="https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215">A Comprehensive Introduction to Different Types of Convolutions in Deep Learning</a></li>
<li><u>parameters</u>: for each layer, parameters number: <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>C</mi><mo>×</mo><mi>k</mi><mo>×</mo><mi>k</mi><mo>×</mo><mi>H</mi><mo>×</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">C \times k \times k \times H \times W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.03148em;">k</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord mathdefault" style="margin-right:0.08125em;">H</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span></li>
</ul>
<p><strong>Conditional attention operation</strong></p>
<ul>
<li><u>role</u>: gate the information flow passed to the next layer.</li>
<li><u> computation </u>: the element-wise product, the same shape with the last output.</li>
</ul>
<h3 id="conditional-weight-predition"><a class="markdownIt-Anchor" href="#conditional-weight-predition"></a> Conditional Weight Predition</h3>
<p>The generator uses different kernels to generate images, but how to get the predicted weights?</p>
<p><strong>Model input</strong></p>
<ul>
<li>Label map</li>
</ul>
<p><strong>Predicted weights</strong><br />
Semantic label maps have some hidden information, such as locations between different stuff. A small receptive field restricts the weight prediction from incorporating long-range context information. So the author introduce “A feature pyramid structure”.</p>
<p><strong>A feature pyramid structure</strong></p>
<ul>
<li><u> process </u>: The features at different levels of the feature pyramid are concatenated with the original semantic map to obtain the global-context-aware semantic feature maps.</li>
<li><u>role</u>: predict weights which are aware of not only local neighborhood, but also long-range context and relative locations.</li>
</ul>
<p><img src="https://tva1.sinaimg.cn/large/008i3skNly1gtyogvi3gkj60r40dm0v902.jpg" alt="" /></p>
<h2 id="feature-pyramid-semantics-embedding-discriminator"><a class="markdownIt-Anchor" href="#feature-pyramid-semantics-embedding-discriminator"></a> Feature Pyramid Semantics Embedding Discriminator</h2>
<p><strong>Drawback of PathGAN</strong></p>
<ul>
<li>Just discriminate whether an image is fake or true, not to keep semantic alignment.</li>
</ul>
<p><strong>Model input</strong></p>
<ul>
<li>an image (GT or generated image)</li>
<li>the label map is used as an additional clues to compute a matching score.</li>
</ul>
<h3 id="semantic-embedding-for-discriminator"><a class="markdownIt-Anchor" href="#semantic-embedding-for-discriminator"></a> Semantic Embedding for Discriminator</h3>
<p><strong>PatchGAN</strong><br />
for each feature map, it classify if each patch is real or not by predicting a score for each spatial location.</p>
<p><strong>Projection discriminator</strong><br />
computes the dot product between the class label and image feature vector as part of the output discriminator score.</p>
<p><strong>Ours</strong></p>
<ul>
<li><u>role</u>: force the discriminator to classify not only real or fake images, but also <strong>whether the patch features match with the semantic labels in that patch</strong> within a joint embedding space.</li>
<li><u>info details</u>: 1)inspired by “Projection discriminator”, calculate the inner product between each spatial location of <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">F_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">F</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span> and <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>S</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">S_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.83333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05764em;">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.05764em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>, to obtain a semantic matching score map; 2) The semantic matching score is <strong>added with</strong> the conventional real/fake score as the final discriminator score.</li>
</ul>
<h2 id="references"><a class="markdownIt-Anchor" href="#references"></a> References</h2>
<ol>
<li>Takeru Miyato and Masanori Koyama. cgans with projection discriminator. arXiv preprint arXiv:1802.05637, 2018.</li>
</ol>
<h2 id="notes"><a class="markdownIt-Anchor" href="#notes"></a> Notes</h2>
<p>I found that some papers you were hardly understand what the content means yesterday, would become easier to read tomorrow…</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://yluy.gitee.io">Sonata</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://yluy.gitee.io/2021/08/30/CC-FPSE/">http://yluy.gitee.io/2021/08/30/CC-FPSE/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/GAN/">GAN</a></div><div class="post_share"><div class="social-share" data-image="https://tva1.sinaimg.cn/large/008i3skNly1gtysla6wewj60rs0rsq8y02.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/09/01/VAE/" title="VAE"><img class="cover" src="https://tva1.sinaimg.cn/large/008i3skNly1gu13bvajnhj61540jgwiz02.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">VAE</div></div></a></div><div class="next-post pull-right"><a href="/2021/08/26/SMIS/" title="SMIS"><img class="cover" src="https://tva1.sinaimg.cn/large/008i3skNly1gtu86uqlj7j60u00u0q8402.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">SMIS</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2021/08/26/Art2Real/" title="Art2Real"><img class="cover" src="https://tva1.sinaimg.cn/large/008i3skNly1gtu8328bcxj60u00u00w802.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-26</div><div class="title">Art2Real</div></div></a></div><div><a href="/2021/08/26/SMIS/" title="SMIS"><img class="cover" src="https://tva1.sinaimg.cn/large/008i3skNly1gtu86uqlj7j60u00u0q8402.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-08-26</div><div class="title">SMIS</div></div></a></div><div><a href="/2020/12/29/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91SIGGRAPH2020%E3%80%8ADeepFaceDrawing%E3%80%8B%E8%8D%89%E5%9B%BE%E5%88%B0%E4%BA%BA%E8%84%B8%E5%9B%BE%E5%83%8F/" title="【论文阅读】SIGGRAPH2020《DeepFaceDrawing》草图到人脸图像"><img class="cover" src="https://tva1.sinaimg.cn/large/0081Kckwly1gm4jiq9pdgj31900u0x6p.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-12-29</div><div class="title">【论文阅读】SIGGRAPH2020《DeepFaceDrawing》草图到人脸图像</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://tva1.sinaimg.cn/large/008i3skNly1gweh81b6pyj30u00u0q49.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Sonata</div><div class="author-info__description">温和安静 爱我所爱</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">87</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">15</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">26</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#topic-and-gap"><span class="toc-number">1.</span> <span class="toc-text"> Topic and Gap</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#topic"><span class="toc-number">1.1.</span> <span class="toc-text"> Topic</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#gap"><span class="toc-number">1.2.</span> <span class="toc-text"> Gap</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#contributions"><span class="toc-number">2.</span> <span class="toc-text"> Contributions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#method-details"><span class="toc-number">3.</span> <span class="toc-text"> Method Details</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#image-generation"><span class="toc-number">3.1.</span> <span class="toc-text"> Image Generation</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#conditional-weight-predition"><span class="toc-number">3.2.</span> <span class="toc-text"> Conditional Weight Predition</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#feature-pyramid-semantics-embedding-discriminator"><span class="toc-number">4.</span> <span class="toc-text"> Feature Pyramid Semantics Embedding Discriminator</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#semantic-embedding-for-discriminator"><span class="toc-number">4.1.</span> <span class="toc-text"> Semantic Embedding for Discriminator</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#references"><span class="toc-number">5.</span> <span class="toc-text"> References</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#notes"><span class="toc-number">6.</span> <span class="toc-text"> Notes</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/07/31/Hexo-%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD%E5%9B%BE%E5%BA%8A%E5%9B%BE%E7%89%87/" title="Hexo 无法加载图床图片"><img src="https://p.ipic.vip/i59ujw.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hexo 无法加载图床图片"/></a><div class="content"><a class="title" href="/2023/07/31/Hexo-%E6%97%A0%E6%B3%95%E5%8A%A0%E8%BD%BD%E5%9B%BE%E5%BA%8A%E5%9B%BE%E7%89%87/" title="Hexo 无法加载图床图片">Hexo 无法加载图床图片</a><time datetime="2023-07-31T07:36:22.000Z" title="Created 2023-07-31 15:36:22">2023-07-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/14/Javascript%E4%BD%9C%E7%94%A8%E5%9F%9F%E4%B8%8E%E9%97%AD%E5%8C%85/" title="Javascript作用域与闭包"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h09a1nnu4hj20u00u00vy.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Javascript作用域与闭包"/></a><div class="content"><a class="title" href="/2022/03/14/Javascript%E4%BD%9C%E7%94%A8%E5%9F%9F%E4%B8%8E%E9%97%AD%E5%8C%85/" title="Javascript作用域与闭包">Javascript作用域与闭包</a><time datetime="2022-03-14T04:01:38.000Z" title="Created 2022-03-14 12:01:38">2022-03-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/14/Javascript%E5%8E%9F%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%9E%8B%E9%93%BE/" title="Javascript原型与原型链"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h099znlnfyj20u00u0402.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Javascript原型与原型链"/></a><div class="content"><a class="title" href="/2022/03/14/Javascript%E5%8E%9F%E5%9E%8B%E4%B8%8E%E5%8E%9F%E5%9E%8B%E9%93%BE/" title="Javascript原型与原型链">Javascript原型与原型链</a><time datetime="2022-03-14T03:59:39.000Z" title="Created 2022-03-14 11:59:39">2022-03-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/03/14/Javascript%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/" title="Javascript异步编程"><img src="https://tva1.sinaimg.cn/large/e6c9d24ely1h099x5m7t3j20u00u0dis.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Javascript异步编程"/></a><div class="content"><a class="title" href="/2022/03/14/Javascript%E5%BC%82%E6%AD%A5%E7%BC%96%E7%A8%8B/" title="Javascript异步编程">Javascript异步编程</a><time datetime="2022-03-14T03:55:11.000Z" title="Created 2022-03-14 11:55:11">2022-03-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/12/17/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/" title="决策树笔记"><img src="https://tva1.sinaimg.cn/large/008i3skNly1gxh4h3d94bj31940u0tig.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="决策树笔记"/></a><div class="content"><a class="title" href="/2021/12/17/%E5%86%B3%E7%AD%96%E6%A0%91%E7%AC%94%E8%AE%B0/" title="决策树笔记">决策树笔记</a><time datetime="2021-12-17T12:48:40.000Z" title="Created 2021-12-17 20:48:40">2021-12-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Sonata</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>