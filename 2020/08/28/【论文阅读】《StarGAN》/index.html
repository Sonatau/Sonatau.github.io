<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>【论文阅读】《StarGAN》 | 私人海域</title><meta name="description" content="论文：《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》 发表时间：CVPR 2018 解决问题：多领域的图像转换问题   背景 Pix2Pix与CycleGAN分别解决了两个领域之间基于匹配数据和非匹配数据的转换。但是在实际的应用中我们会发现需要大量的多领域"><meta name="keywords" content="中等"><meta name="author" content="Sonata,sonatau@163.com"><meta name="copyright" content="Sonata"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="https://tva1.sinaimg.cn/large/007S8ZIlly1ghwjtdrp4tj30rs0rsjwe.jpg"><link rel="canonical" href="http://yluy.gitee.io/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta property="og:type" content="article"><meta property="og:title" content="【论文阅读】《StarGAN》"><meta property="og:url" content="http://yluy.gitee.io/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/"><meta property="og:site_name" content="私人海域"><meta property="og:description" content="论文：《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》 发表时间：CVPR 2018 解决问题：多领域的图像转换问题   背景 Pix2Pix与CycleGAN分别解决了两个领域之间基于匹配数据和非匹配数据的转换。但是在实际的应用中我们会发现需要大量的多领域"><meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bwff3axj318g0p0ac5.jpg"><meta property="article:published_time" content="2020-08-28T02:42:42.000Z"><meta property="article:modified_time" content="2020-08-28T02:44:21.293Z"><meta name="twitter:card" content="summary"><script>var activateDarkMode = function () {
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#000')
  }
}
var activateLightMode = function () {
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null) {
    document.querySelector('meta[name="theme-color"]').setAttribute('content', '#fff')
  }
}

var getCookies = function (name) {
  const value = `; ${document.cookie}`
  const parts = value.split(`; ${name}=`)
  if (parts.length === 2) return parts.pop().split(';').shift()
}

var autoChangeMode = 'false'
var t = getCookies('theme')
if (autoChangeMode === '1') {
  var isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
  var isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
  var isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined) {
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport) {
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour <= 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
    }
    window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
      if (Cookies.get('theme') === undefined) {
        e.matches ? activateDarkMode() : activateLightMode()
      }
    })
  } else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else if (autoChangeMode === '2') {
  now = new Date()
  hour = now.getHours()
  isNight = hour <= 6 || hour >= 18
  if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode()
} else {
  if (t === 'dark') activateDarkMode()
  else if (t === 'light') activateLightMode()
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web&amp;display=swap"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.0.2',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: false,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  isPhotoFigcaption: true,
  islazyload: true,
  isanchor: false    
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2020-08-28 10:44:21'
}</script><noscript><style>
#nav {
  opacity: 1
}
.justified-gallery img {
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 5.0.2"></head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghwjow3dndj30jg0jgdgq.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">24</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">3</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">14</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF"><span class="toc-number">1.</span> <span class="toc-text"> 背景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="toc-number">2.</span> <span class="toc-text"> 网络架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E6%A0%87%E5%87%BD%E6%95%B0"><span class="toc-number">3.</span> <span class="toc-text"> 目标函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E6%9E%9C"><span class="toc-number">4.</span> <span class="toc-text"> 结果</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bwff3axj318g0p0ac5.jpg)"><nav id="nav"><span class="pull-left" id="blog_name"><a class="blog_title" id="site-name" href="/">私人海域</a></span><span class="pull-right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">【论文阅读】《StarGAN》</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2020-08-28T02:42:42.000Z" title="发表于 2020-08-28 10:42:42">2020-08-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2020-08-28T02:44:21.293Z" title="更新于 2020-08-28 10:44:21">2020-08-28</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读笔记</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><blockquote>
<p>论文：《StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation》</p>
<p>发表时间：CVPR 2018</p>
<p>解决问题：多领域的图像转换问题</p>
</blockquote>
<h2 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h2>
<p>Pix2Pix与CycleGAN分别解决了两个领域之间基于匹配数据和非匹配数据的转换。但是在实际的应用中我们会发现需要大量的多领域转换，例如图1所示，这可能是一个智能修图的场景，用户输入一张人物照片，他希望能够通过选项来调节照片中人物的外貌，比如图中例子的发色、性别、年龄、肤色等。又比如图2，对于同一个人物照片我们希望能够将他转换成各种不一样的表情，从普通的表情转换为愤怒、喜悦和恐惧等。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghvy75rvdjj30rs0nzdxg.jpg" alt="图1 头像照片的多种外貌转换" style="width:50%">
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghvy775araj30rs0rte1y.jpg" alt="图2 头像照片的多种表情转换" style="width:50%">
<p>之前的Pix2Pix和CycleGAN可以非常好地解决领域间转换问题，它们同样可以应用于多领域的转换，但是存在的问题是必须在每两个领域之间进行单独的训练。我们假设场景为图8-3的表情转换，一共有四个领域，分别为中性、生气、喜悦与恐惧，我们将它们从1到4标号。如果使用CycleGAN的话我们可以看到图3，在每两个领域都需要训练两个生成器，比如领域1和领域3之间，就需要有生成器G31与生成器G13，分别作为从3到1和从1到3的生成。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghvyatd2kej30r80pdwm5.jpg" alt="图3 使用CycleGAN实现多领域转换的情况" style="width:50%">
<p>我们会发现，在四个领域的情况下已经需要12个不同的生成器了，随着领域数量的增加，该数量会越来越大，如果领域的数量为n的话，排列组合的数量为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>C</mi><mi>n</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">C_n ^ 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.061108em;vertical-align:-0.247em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07153em;">C</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8141079999999999em;"><span style="top:-2.4530000000000003em;margin-left:-0.07153em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">n</span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span>￼。在领域很多的情况下，要训练这么多生成模型是非常消耗资源的。<br />
此外，除了在训练过程中的资源消耗以外，StarGAN的研究者还发现如果仅使用CycleGAN的方法在每两个领域之间进行生成器的训练，那么各自的训练过程都是独立的，这导致比如像图2中虽然每个领域是不一样的表情，但是人脸的结构是基本一致的，<strong>独立的训练会浪费大量可以辅助优化生成器的数据</strong>，这显然也是不合理的。针对这两个问题，研究者们希望能够为这样的多领域转换找到一个更加合适的解决方案。</p>
<p>StarGAN的论文在2017年年底发布在了arxiv上，并随后发表在了计算机视觉领域会议CVPR2018。StarGAN提供了一种针对多领域的解决方案，<strong>在多领域转换的情况下仅需训练一个通用的生成器即可</strong>。图4是StarGAN的结构示意图，对于五个领域的情况仅需中间的一个生成器G即可，整个网络形成一个星形的拓扑结构，这也是StarGAN的命名由来。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghvygn9f2tj30jq0j3djv.jpg" alt="图4 使用StarGAN实现多领域转换的情况" style="width:50%">
<h2 id="网络架构"><a class="markdownIt-Anchor" href="#网络架构"></a> 网络架构</h2>
<p>StarGAN的网络设计借鉴了很多经典的思想，其中最重要的正是Cycle-GAN和cGAN。首先我们看一下StarGAN的网络结构，其判别器如图8-5所示，输入为任意分类的真伪图片，输出部分需要将所有数据都进行真伪判断，对真数据还需要进行所属领域的分类，这一判别器非常类似前面介绍的ACGAN。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghvytyjx6mj30u00vz15m.jpg" alt="图5 StarGAN判别器结构图" style="width:50%">
<p>图6展示了StarGAN比较完整的流程，<strong>对于生成器的输入不仅需要原始图片，同时还需要像cGAN一样设定一个目标领域。由生成器产生的图像会进入上面所说的判别器中进行判定，目标是让判别器将其判定为真实图像且属于目标领域。与此同时该生成图像还需要再次输入本身的生成器中，且将输入条件设置为源领域，用于重建原始图像，确保重建的图像能够与原始图像越接近越好。</strong></p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghvywv0in5j30rs0dt0wp.jpg" alt="图6 StarGAN完整结构图" style="width:50%">
<h2 id="目标函数"><a class="markdownIt-Anchor" href="#目标函数"></a> 目标函数</h2>
<p>根据上述网络架构，我们来看一下StarGAN的目标函数。</p>
<p>首先是常规的<strong>GAN对抗损失函数</strong>，也就是生成器能否让判别器认为该生成图像为真实图像，其中c为条件参数，表示目标类型。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghvz0uoh57j30rs01k3yx.jpg" style="width:50%">
<p>其次是<strong>分类损失</strong>，同样也要同时对生成器和判别器进行优化，这里可以写成两种分类损失：第一种是对于真数据的分类损失<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow><mi>r</mi></msubsup></mrow><annotation encoding="application/x-tex">L_{cls}^r</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9664379999999999em;vertical-align:-0.2831079999999999em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.664392em;"><span style="top:-2.4168920000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2831079999999999em;"><span></span></span></span></span></span></span></span></span></span>￼，第二种是假数据的分类损失￼<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>L</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow><mi>f</mi></msubsup></mrow><annotation encoding="application/x-tex">L_{cls}^f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2683239999999998em;vertical-align:-0.3013079999999999em;"></span><span class="mord"><span class="mord mathdefault">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9670159999999999em;"><span style="top:-2.3986920000000005em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span><span style="top:-3.1809080000000005em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10764em;">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3013079999999999em;"><span></span></span></span></span></span></span></span></span></span>￼对应下面两个公式。</p>
<p>其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>D</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">′</mi><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">D_{cls}(c′|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord">′</span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>代表判别器将真实输入x归为原始分类c′的判别概率分布，(x,c′)是真实训练数据中的分类匹配数据，判别器D的目标是最小化这个损失函数。另一方面，对于生成器来说希望基于x的生成数据能够被判别器判断为目标分类c，需要G能够最小化损失函数￼。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghw3ilsp6jj30rs03iq3p.jpg" style="width:50%">
<p>再清楚一点说，就是当给定一个输入图像x属于c’领域，将它投入判别器，判别器的目标就是尽可能分辨出x时属于c’类的，因此<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><msub><mi>D</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><msup><mi>c</mi><mo mathvariant="normal">′</mo></msup><mi mathvariant="normal">∣</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">logD_{cls}(c&#x27;|x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.001892em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.751892em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">′</span></span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span>就要尽可能得大。另外，当将目标领域和输入图像都投入生成器后的结果作为新的输入，被判别器判断为是c的可能性应该尽可能得大，所以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><msub><mi>D</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>G</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">logD_{cls}(c|G(x, c))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.01968em;">l</span><span class="mord mathdefault">o</span><span class="mord mathdefault" style="margin-right:0.03588em;">g</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">c</span><span class="mord">∣</span><span class="mord mathdefault">G</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault">c</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>要尽可能大。</p>
<p>最终我们还需构建<strong>重建损失</strong>，确保生成的数据能够很好地还原到本来的领域分类中。这里使用原始数据和经过两次生成（先转换到分类c，再转换为源分类c′）的图像L1损失作为重建损失（CycleGAN），公式如下所示。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghw3o7k22pj30rs01kq37.jpg" style="width:50%">
<p>最终的目标函数如下，分为判别器与生成器。其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub></mrow><annotation encoding="application/x-tex">λ_{cls}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi>r</mi><mi>e</mi><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">λ_{rec}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为超参数，用来控制分类损失、重建损失相对于对抗损失的重要性，在StarGAN原文的实验中取<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi>c</mi><mi>l</mi><mi>s</mi></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">λ_{cls}=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">c</span><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span><span class="mord mathdefault mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.64444em;vertical-align:0em;"></span><span class="mord">1</span></span></span></span>和<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>λ</mi><mrow><mi>r</mi><mi>e</mi><mi>c</mi></mrow></msub></mrow><annotation encoding="application/x-tex">λ_{rec}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">λ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">e</span><span class="mord mathdefault mtight">c</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>=10。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghw3rlg640j30rs03haao.jpg" style="width:50%">
<p>StarGAN的另外一个创新点在于能够同时协调多个包含不同领域的数据集，比如图1的外貌数据集和图2的表情数据集。但这里存在的问题是两个数据集之间是不知道对方的分类标签是什么的，比如外貌数据集只知道自己包含发色、肤色等，却不知道表情数据集包含了喜悦、愤怒等。</p>
<p>在StarGAN中，研究者们加入了<strong>一个Mask向量m的概念，用来忽略那些未知的分类</strong>，仅关注于自身了解的分类。最终的分类标签向量如下所示，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>c</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">c_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>用来表示第i个数据库的分类信息。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghw3u4xwpuj30rs01udfy.jpg" style="width:50%">
<p>在训练过程中，会将上式中的￼直接输入生成器作为条件信息，由于Mask向量的存在，那些无关的分类标签向量会变成零向量，生成器会自动忽略。另一方面在多任务的训练中，判别器也仅会对自己了解的分类进行判别。图7是使用两个多分类数据库同时训练的框架图，使用的就是外貌数据集和表情数据集，可以看到Mask向量分别在两种数据库的情况下对应为[1, 0]和[0, 1]，会将不属于该数据库的分类标签向量置为全零。在这样的多数据库训练过程后，判别器会具备各个数据库的分类判别能力，而生成器也可以同时针对多个数据库的信息进行图像生成。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghw44d8vp1j30rs0ru4ep.jpg" alt="图7 StarGAN同时训练两个多分类数据库的框架示意图" style="width:50%">
<h2 id="结果"><a class="markdownIt-Anchor" href="#结果"></a> 结果</h2>
<p>图8和图9是官方给出的最终生成效果图，分别对应上文提到的外貌数据库与表情数据库，读者可以自己按照上述步骤尝试使用一下多分类的转换。</p>
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghw46o6fdaj30rs0kf1gg.jpg" alt="图8 StarGAN的多种外貌生成效果图" style="width:50%">
<img src= "/img/loading.gif" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1ghw49yhhl1j30rs0mn1fj.jpg" alt="图8-9 StarGAN的多种表情生成效果图" style="width:50%">
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:sonatau@163.com">Sonata</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://yluy.gitee.io/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/">http://yluy.gitee.io/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8AStarGAN%E3%80%8B/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://yluy.gitee.io" target="_blank">私人海域</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E4%B8%AD%E7%AD%89/">中等</a></div><div class="post_share"><div class="social-share" data-image="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bwff3axj318g0p0ac5.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2020/08/29/%E3%80%90%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E3%80%91%E5%9B%BE%E5%83%8F%E8%BD%AE%E5%BB%93/"><img class="prev-cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi7jwhy37fj31de0rs4fs.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">【图像处理】图像轮廓</div></div></a></div><div class="next-post pull-right"><a href="/2020/08/28/%E3%80%90%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E3%80%91%E3%80%8APix2Pix%E3%80%8B/"><img class="next-cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bthvkq1j315o0mzwj5.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【论文阅读】《Pix2Pix》</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/08/24/【图像处理】Harris特征点检测/" title="【图像处理】Harris特征点检测"><img class="relatedPosts_cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi2bbz5079j31hc0u0qfo.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-24</div><div class="relatedPosts_title">【图像处理】Harris特征点检测</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/29/【机器学习】K近邻算法原理与实践/" title="【机器学习】K近邻算法原理与实践"><img class="relatedPosts_cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi80z5ja2uj31hc0u0ag1.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-29</div><div class="relatedPosts_title">【机器学习】K近邻算法原理与实践</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/24/【算法专题】栈和队列/" title="【算法专题】栈和队列"><img class="relatedPosts_cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi2cffi8o1j30jg0axwhd.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-24</div><div class="relatedPosts_title">【算法专题】栈和队列</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/25/【算法专题】并查集/" title="【算法专题】并查集"><img class="relatedPosts_cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi2cr5vgqgj30k00cimxj.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-25</div><div class="relatedPosts_title">【算法专题】并查集</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/23/【算法提高】链表专题题解汇总/" title="【算法提高】链表专题题解汇总"><img class="relatedPosts_cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi0kxdh4nyj31hc0u0ka8.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-23</div><div class="relatedPosts_title">【算法提高】链表专题题解汇总</div></div></a></div><div class="relatedPosts_item"><a href="/2020/08/28/【论文阅读】《CycleGAN》/" title="【论文阅读】《CycleGAN》"><img class="relatedPosts_cover" data-lazy-src="https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bnm0kjvj318g0p047b.jpg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="far fa-calendar-alt fa-fw"></i> 2020-08-28</div><div class="relatedPosts_title">【论文阅读】《CycleGAN》</div></div></a></div></div></div></article></main><footer id="footer" style="background-image: url(https://tva1.sinaimg.cn/large/007S8ZIlly1gi6bwff3axj318g0p0ac5.jpg)" data-type="photo"><div id="footer-wrap"><div class="copyright">&copy;2020 By Sonata</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">hi there ~</div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font_plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font_minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module" defer></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js" async></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>$(function () {
  $('span.katex-display').wrap('<div class="katex-wrap"></div>')
})</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="ribbon_piao" mobile="false" src="/js/third-party/piao.js"></script><script src="/js/third-party/click_heart.js" async="async"></script></div></body></html>